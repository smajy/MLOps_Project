\section{مدل}

\subsection{نامزدهای مدل مناسب را انتخاب کنید}


مسئله ما یکی از مسئله‌های معروف پرسش و پاسخ در حوزه پردازش زبان های طبیع است که پیچیدگی نسبتا زیادی برای حل این مسئله وجود دارد.
به اینگونه که اگر انسانی بخواهد به پرسش ها واسخ دهد باید حتما با علم و دانش پاسخ گو باشد
خروجی دلخواهی که از آن مد نظرمان است این است که بتوانیم با دادن هر سوال ، پاسخ متناسب با آن را دریافت کنیم.\\

چندی از مدل‌های قابل طراحی را ذکر میکنیم:
\begin{itemize}
    \item شبکه های عصبی بازگشتی (RNN):\\
    RNN ها مانند LSTM (حافظه کوتاه مدت بلند مدت) یا GRU (واحد بازگشتی دروازه ای) برای پردازش داده های متوالی مناسب هستند. آنها می توانند اطلاعات متنی و وابستگی های متن را به تصویر بکشند و آنها را برای انجام وظایف پرسش و پاسخ مناسب کنند.\\
    \item شبکه های عصبی بازگشتی (GRU):\\
    GRU (Gated Recurrent Unit) یک نوع مدل شبکه عصبی بازگشتی (RNN) است که برای پردازش داده‌های توالی مانند پردازش زبان طبیعی و تحلیل سری زمانی استفاده می‌شود.
    \item مدل‌های مبتنی بر ترانسفورماتور:\\
    مدل‌های ترانسفورماتور مانند BERT (نمایش رمزگذار دوطرفه از ترانسفورماتور) یا GPT (ترانسفورماتور از پیش آموزش‌دیده مولد)، موفقیت چشمگیری در وظایف پردازش زبان طبیعی به دست آورده‌اند. این مدل‌ها از مکانیسم‌های خودتوجهی برای به تصویر کشیدن روابط بین کلمات در متن استفاده می‌کنند و عملکرد قوی در وظایف پاسخ‌گویی به سؤال از خود نشان داده‌اند.\\
    \item شبکه های عصبی کانولوشن (CNN):\\
    CNN ها معمولاً برای پردازش تصویر استفاده می شوند، اما می توانند روی داده های متنی نیز اعمال شوند. با استفاده از کانولوشن های 1 بعدی، CNN ها می توانند الگوها و ویژگی های محلی را در متن ثبت کنند، که می تواند برای وظایف پرسش و پاسخ مفید باشد.\\
    \item شبکه های حافظه:\\
    شبکه های حافظه به طور خاص برای انجام وظایف پرسش و پاسخ طراحی شده اند. آنها از یک جزء حافظه خارجی برای ذخیره و بازیابی اطلاعات مربوط به سؤالات استفاده می کنند و آنها را قادر می سازد تا با سؤالات و سناریوهای استدلالی پیچیده تری رسیدگی کنند.\\
    \item مجموعه مدل ها:\\
    همانطور که قبلا ذکر شد، تکنیک های یادگیری گروهی می تواند برای بهبود عملکرد مدل مفید باشد. می توانید مجموعه ای از مدل های مختلف ایجاد کنید و پیش بینی های آنها را برای دستیابی به نتایج بهتر ترکیب کنید. به عنوان مثال، می توانید خروجی های یک RNN، یک مدل ترانسفورماتور و یک CNN را ترکیب کنید تا از نقاط قوت مربوطه استفاده کنید.\\
\end{itemize} 


\subsection{معیارهای ارزیابی و رویه های ارزیابی خود را تنظیم کنید}

\begin{itemize}
    \item Accuracy \\
    این متریک درصد سوالاتی که به درستی پاسخ داده شده اند را اندازه گیری می کند. تعداد سؤالاتی را محاسبه می کند که در آن پاسخ پیش بینی شده با پاسخ حقیقت اصلی مطابقت دارد و آن را بر تعداد کل سؤالات تقسیم می کند.
    \item BLEU\\
    نمره دو زبانه ارزیابی زیرمجموعه (BLEU) معمولاً در کارهای ترجمه ماشینی استفاده می‌شود، اما می‌تواند برای مدل‌های پرسش و پاسخ نیز تطبیق داده شود. این شباهت بین پاسخ پیش‌بینی‌شده و پاسخ حقیقت پایه را با مقایسه همپوشانی‌های n-gram اندازه‌گیری می‌کند.
    \item ROUGE\\
    نمره فراخوانی گرا برای ارزیابی Gisting (ROUGE) یکی دیگر از معیارهای ارزیابی است که معمولاً در کارهای خلاصه سازی متن استفاده می شود. همپوشانی بین پاسخ پیش‌بینی‌شده و پاسخ حقیقت پایه را بر حسب n-گرم و skip-bigram اندازه‌گیری می‌کند.

\end{itemize}

\subsection{فرآیند آموزش}
در این قسمت توضیحاتی در مورد داده و مدل آموزش داده شده داده می‌شود
\subsubsection{آماده سازی داده برای ورودی مدل}
ما در اینجا چندین جفت داده داریم، یکی برای پرسش و دیگری برای پاسخ آن پرسش مطرح می‌شود.
در اینجا باید بتوانیم هر جمله را به صورت لیستی از کلمات داشته باشیم و یک زبان از تمامی کلمات خود ایجاد کنیم، به این صورت که هر 
اندیس نمایانگر یک کلمه باشد، البته باید به کاراکترهای جانبی نیز دقت کنیم.
برای شروع آمادیم یک کلاس ساختیم تا بتوانیم ارتباط بین جملات و کلمات و اندیس ها برقرار کنیم
کلاس VOC نمایانگر چنین کلاسی است.\\
سه تگ اضافی شامل SOS نمایانگر شروع جمله و تگ EOS نمایاگر پایان جمله و تگ PAD نمایان گر فضای خالی است.\\

یک فیلتر تایین کردیم تا بتوانیم جملات به حداکثر کلمه مشخص را به مدل بدهیم.\\
داده‌های آموزشی را آماده و در کلاس VOC لود میکنیم.\\

یک فیلتر دیگه برای کلمات قرار دادیم که تعداد تکرار کلمات را نیز بتوانیم بررسی کنیم به این صورت که اگر کمترین کلمه را 3 در نظر بگیریم
هر کلمه ای که کمتر از 3 بار تکرار شده باشد دیگر در نظر گرفته نمیشود.\\
در این روش میتواند داده‌ها را کم کند.\\

کدی را پیاده کردیم که بتونیم داده را به صورت بسته بسته بتوانیم به مدل بدهیم.\\
داده ورودی را با اضافه توکن های خاص به فضایی تنسور میبریم.\\
داده خروجی را نیز با اضافه کاراکتر اضافی به فضای تنسور میبریم و مسکی از آن‌ها نیز میسازیم.\\

\subsubsection{مدل آموزشی}
در مدل آموزشی از یک encode , decoder استفاده میکنیم
در encoder با توجه به تعداد لایه ها و تعدا لایه های پنهان امبدینگ موجود به همراه مدل GRU میسازیم
از decoder با توجه به تعداد لایه ها و لایه های پنهان و امبدینگ موجود به همراه مل GRU , Attention میسازیم

دوتا encoder , decoder را در آموزشی مدل بهبود میبخشیم و آن‌ها را با توجه به داده‌ها آموزش میدهیم.
